'use client';

import { useState, useRef, useEffect, useReducer } from 'react';
import { Mic, MicOff, Volume2, Loader2, MessageSquare } from 'lucide-react';

// ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Speech Recognition
function isSpeechRecognitionSupported(): boolean {
  return typeof window !== 'undefined' && ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window);
}

// ØªØ§Ø¨Ø¹ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØµØ¯Ø§
async function enableAudio(): Promise<void> {
  if (typeof window === 'undefined') return;
  
  try {
    const AudioContext = window.AudioContext || (window as any).webkitAudioContext;
    const audioContext = new AudioContext();
    
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }
    
    console.log('Audio enabled successfully');
  } catch (error) {
    console.error('Failed to enable audio:', error);
    throw error;
  }
}

// ØªØ§Ø¨Ø¹ Ø´Ø±ÙˆØ¹ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†
function startListening(callbacks: {
  onResult: (text: string) => void;
  onEnd: (finalText: string) => void;
  onError: (error: string) => void;
}): any {
  if (!isSpeechRecognitionSupported()) {
    callbacks.onError('ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯');
    return null;
  }

  const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  
  recognition.lang = 'fa-IR';
  recognition.continuous = false;
  recognition.interimResults = true;
  
  let finalTranscript = '';
  
  recognition.onresult = (event: any) => {
    let interimTranscript = '';
    
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript + ' ';
      } else {
        interimTranscript += transcript;
      }
    }
    
    callbacks.onResult(finalTranscript + interimTranscript);
  };
  
  recognition.onend = () => {
    callbacks.onEnd(finalTranscript.trim());
  };
  
  recognition.onerror = (event: any) => {
    callbacks.onError(`Ø®Ø·Ø§: ${event.error}`);
  };
  
  recognition.start();
  return recognition;
}

// ØªØ§Ø¨Ø¹ ØªÙˆÙ‚Ù Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†
function stopListening(recognition: any): void {
  if (recognition) {
    recognition.stop();
  }
}

// ØªØ§Ø¨Ø¹ Ù¾Ø®Ø´ ØµØ¯Ø§
async function playAudio(text: string): Promise<void> {
  try {
    const response = await fetch('/api/voice-assistant/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ text }),
    });

    if (!response.ok) {
      throw new Error('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµØ¯Ø§');
    }

    const data = await response.json();
    
    if (!data.success || !data.audioUrl) {
      throw new Error(data.error || 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµØ¯Ø§');
    }

    // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² audioUrl Ú©Ù‡ Ø§Ø² API Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯Ù‡
    const audio = new Audio(data.audioUrl);
    
    await audio.play();
    
    return new Promise((resolve, reject) => {
      audio.onended = () => {
        resolve();
      };
      audio.onerror = (e) => {
        console.error('Audio playback error:', e);
        reject(new Error('Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø®Ø´ ØµØ¯Ø§'));
      };
    });
  } catch (error) {
    console.error('Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø®Ø´ ØµØ¯Ø§:', error);
    throw error;
  }
}

// State management
interface Message {
  user: string;
  robin: string;
  timestamp: Date;
}

interface State {
  isListening: boolean;
  isProcessing: boolean;
  isPlaying: boolean;
  currentMessage: string;
  error: string | null;
  microphonePermission: boolean;
  history: Message[];
}

type Action =
  | { type: 'SET_LISTENING'; payload: boolean }
  | { type: 'SET_PROCESSING'; payload: boolean }
  | { type: 'SET_PLAYING'; payload: boolean }
  | { type: 'SET_CURRENT_MESSAGE'; payload: string }
  | { type: 'SET_ERROR'; payload: string | null }
  | { type: 'SET_MIC_PERMISSION'; payload: boolean }
  | { type: 'ADD_MESSAGE'; payload: Message }
  | { type: 'CLEAR_HISTORY' };

function reducer(state: State, action: Action): State {
  switch (action.type) {
    case 'SET_LISTENING':
      return { ...state, isListening: action.payload };
    case 'SET_PROCESSING':
      return { ...state, isProcessing: action.payload };
    case 'SET_PLAYING':
      return { ...state, isPlaying: action.payload };
    case 'SET_CURRENT_MESSAGE':
      return { ...state, currentMessage: action.payload };
    case 'SET_ERROR':
      return { ...state, error: action.payload };
    case 'SET_MIC_PERMISSION':
      return { ...state, microphonePermission: action.payload };
    case 'ADD_MESSAGE':
      return { ...state, history: [...state.history, action.payload] };
    case 'CLEAR_HISTORY':
      return { ...state, history: [] };
    default:
      return state;
  }
}

const initialState: State = {
  isListening: false,
  isProcessing: false,
  isPlaying: false,
  currentMessage: '',
  error: null,
  microphonePermission: false,
  history: []
};

export default function VoiceAssistantPage({ params }: { params: { tenant_key: string } }) {
  const tenantKey = params.tenant_key || 'rabin';
  
  // Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø² localStorage
  const loadHistoryFromStorage = () => {
    if (typeof window === 'undefined') return [];
    try {
      const stored = localStorage.getItem(`voice-history-${tenantKey}`);
      if (stored) {
        const parsed = JSON.parse(stored);
        // ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ Date object
        return parsed.map((msg: any) => ({
          ...msg,
          timestamp: new Date(msg.timestamp)
        }));
      }
    } catch (error) {
      console.error('Error loading history:', error);
    }
    return [];
  };

  const [state, dispatch] = useReducer(reducer, {
    ...initialState,
    history: loadHistoryFromStorage()
  });
  const [showHistory, setShowHistory] = useState(false);
  const [buttonText, setButtonText] = useState('Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯Ùˆ');
  const recognitionRef = useRef<any>(null);
  const autoStartRef = useRef<boolean>(false);
  const historyRef = useRef<Message[]>(state.history); // Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù‡ÛŒØ³ØªÙˆØ±ÛŒ Ø¯Ø± ref

  // Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ historyRef Ù‡Ø± Ø¨Ø§Ø± Ú©Ù‡ state.history ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ù‡
  useEffect(() => {
    historyRef.current = state.history;
  }, [state.history]);

  // Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø± localStorage Ù‡Ø± Ø¨Ø§Ø± Ú©Ù‡ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ù‡
  useEffect(() => {
    if (typeof window !== 'undefined' && state.history.length > 0) {
      try {
        localStorage.setItem(`voice-history-${tenantKey}`, JSON.stringify(state.history));
        console.log(`ğŸ’¾ History saved: ${state.history.length} messages`);
      } catch (error) {
        console.error('Error saving history:', error);
      }
    }
  }, [state.history, tenantKey]);

  // Check microphone permission on mount
  useEffect(() => {
    const checkPermission = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        dispatch({ type: 'SET_MIC_PERMISSION', payload: true });
        
        // Auto-enable audio
        await enableAudio();
        
        // Auto-start listening
        dispatch({ type: 'SET_LISTENING', payload: true });
      } catch (error) {
        console.error('Microphone permission denied:', error);
        dispatch({ type: 'SET_MIC_PERMISSION', payload: false });
        dispatch({ type: 'SET_ERROR', payload: 'Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù„Ø§Ø²Ù… Ø§Ø³Øª' });
      }
    };

    checkPermission();
  }, []);

  // Auto-start listening when permission is granted
  useEffect(() => {
    if (state.microphonePermission && state.isListening && !autoStartRef.current) {
      autoStartRef.current = true;
      startListeningProcess();
    }
  }, [state.microphonePermission, state.isListening]);

  const startListeningProcess = async () => {
    if (!state.microphonePermission) {
      dispatch({
        type: 'SET_ERROR',
        payload: 'Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù„Ø§Ø²Ù… Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ØµÙØ­Ù‡ Ø±Ø§ Ø±ÙØ±Ø´ Ú©Ù†ÛŒØ¯ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø±Ø§ Ø¨Ø¯Ù‡ÛŒØ¯.'
      });
      return;
    }

    dispatch({ type: 'SET_ERROR', payload: null });
    setButtonText('Ø¯Ø± Ø­Ø§Ù„ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†...');

    try {
      recognitionRef.current = startListening({
        onResult: (transcript: string) => {
          dispatch({ type: 'SET_CURRENT_MESSAGE', payload: transcript });
        },
        onEnd: async (finalTranscript: string) => {
          dispatch({ type: 'SET_LISTENING', payload: false });
          setButtonText('Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...');

          const messageToSend = finalTranscript.trim() || state.currentMessage.trim();
          if (messageToSend) {
            dispatch({ type: 'SET_PROCESSING', payload: true });

            try {
              // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² historyRef Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ù‡ÛŒØ³ØªÙˆØ±ÛŒ
              const currentHistory = historyRef.current;
              
              console.log('ğŸ“¤ Sending to AI:', {
                message: messageToSend.substring(0, 50),
                historyCount: currentHistory.length
              });

              // Call AI API with timeout
              const controller = new AbortController();
              const timeoutId = setTimeout(() => controller.abort(), 55000); // 55 second timeout

              const response = await fetch('/api/voice-assistant/ai', {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'X-Tenant-Key': tenantKey,
                },
                body: JSON.stringify({
                  userMessage: messageToSend,
                  history: currentHistory
                }),
                signal: controller.signal
              });

              clearTimeout(timeoutId);

              if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                console.error('âŒ API Error:', response.status, errorData);
                throw new Error(errorData.error || 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² AI');
              }

              const data = await response.json();
              console.log('âœ… AI Response received');
              const responseText = data.response || 'Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ù¾Ø§Ø³Ø® Ù…Ù†Ø§Ø³Ø¨ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ù….';

              // Add to history
              dispatch({
                type: 'ADD_MESSAGE',
                payload: {
                  user: finalTranscript,
                  robin: responseText,
                  timestamp: new Date(),
                },
              });

              // Play audio response
              dispatch({ type: 'SET_PLAYING', payload: true });
              setButtonText('Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø®Ø´...');

              try {
                await playAudio(responseText);
              } catch (audioError) {
                console.error('Audio playback failed:', audioError);
                dispatch({
                  type: 'SET_ERROR',
                  payload: 'Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ Ø§Ù…Ø§ Ù¾Ø®Ø´ ØµØ¯Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.'
                });
              }

              dispatch({ type: 'SET_PLAYING', payload: false });

              // Auto-restart listening after response
              setTimeout(() => {
                if (state.microphonePermission) {
                  dispatch({ type: 'SET_LISTENING', payload: true });
                  startListeningProcess();
                }
              }, 500);

            } catch (error: any) {
              console.error('âŒ Error processing message:', error);
              
              let errorMessage = 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.';
              
              if (error.name === 'AbortError') {
                errorMessage = 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø´Ø¯ Ùˆ Ù‚Ø·Ø¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.';
              } else if (error.message) {
                errorMessage = error.message;
              }
              
              dispatch({
                type: 'SET_ERROR',
                payload: errorMessage
              });
              setButtonText('Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯Ùˆ');
            } finally {
              dispatch({ type: 'SET_PROCESSING', payload: false });
              dispatch({ type: 'SET_CURRENT_MESSAGE', payload: '' });
            }
          } else {
            // Auto-restart listening if no speech detected
            setTimeout(() => {
              if (state.microphonePermission) {
                dispatch({ type: 'SET_LISTENING', payload: true });
                startListeningProcess();
              }
            }, 500);
          }
        },
        onError: (error: string) => {
          dispatch({ type: 'SET_LISTENING', payload: false });
          dispatch({ type: 'SET_ERROR', payload: error });
          setButtonText('Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯Ùˆ');

          // Auto-restart listening after error
          setTimeout(() => {
            dispatch({ type: 'SET_LISTENING', payload: true });
            startListeningProcess();
          }, 2000);
        },
      });
    } catch (error) {
      dispatch({ type: 'SET_LISTENING', payload: false });
      dispatch({
        type: 'SET_ERROR',
        payload: 'Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.'
      });
      setButtonText('Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯Ùˆ');
    }
  };

  const handleMicrophoneClick = async () => {
    // Enable audio on first user interaction
    await enableAudio();
    
    if (state.isListening) {
      // Stop listening
      stopListening(recognitionRef.current);
      dispatch({ type: 'SET_LISTENING', payload: false });
      setButtonText('Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯Ùˆ');
      autoStartRef.current = false;
    } else if (state.isProcessing || state.isPlaying) {
      // Cannot start while processing or playing
      return;
    } else {
      // Start listening manually
      dispatch({ type: 'SET_LISTENING', payload: true });
      startListeningProcess();
      setButtonText('Ø¯Ø± Ø­Ø§Ù„ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†...');
    }
  };

  const getButtonState = () => {
    if (state.isListening) return 'listening';
    if (state.isProcessing) return 'processing';
    if (state.isPlaying) return 'playing';
    return 'ready';
  };

  const getButtonClasses = () => {
    const baseClasses = 'w-32 h-32 md:w-40 md:h-40 rounded-full border-4 border-white shadow-2xl transition-all duration-300 flex flex-col items-center justify-center text-white font-bold';

    switch (getButtonState()) {
      case 'listening':
        return `${baseClasses} bg-yellow-500 animate-pulse cursor-pointer`;
      case 'processing':
        return `${baseClasses} bg-orange-500 cursor-not-allowed`;
      case 'playing':
        return `${baseClasses} bg-blue-500 animate-pulse cursor-not-allowed`;
      default:
        return `${baseClasses} bg-green-600 hover:bg-green-700 cursor-pointer`;
    }
  };

  const renderIcon = () => {
    const iconSize = 32;

    switch (getButtonState()) {
      case 'listening':
        return <Mic size={iconSize} className="mb-1" />;
      case 'processing':
        return <Loader2 size={iconSize} className="mb-1 animate-spin" />;
      case 'playing':
        return <Volume2 size={iconSize} className="mb-1" />;
      default:
        return state.microphonePermission ?
          <Mic size={iconSize} className="mb-1" /> :
          <MicOff size={iconSize} className="mb-1" />;
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-green-100 to-green-200">
      {/* Header */}
      <header className="text-center py-8 relative">
        <h1 className="text-4xl font-bold text-green-800 mb-2">
          Ø¯Ø³ØªÛŒØ§Ø± Ø±Ø§Ø¨ÛŒÙ†
        </h1>
        <p className="text-lg text-green-600">
          Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ØµÙˆØªÛŒ Ø´Ù…Ø§
        </p>
        
        {/* History Toggle Button */}
        <button
          onClick={() => setShowHistory(!showHistory)}
          className="absolute top-8 left-8 bg-white p-3 rounded-full shadow-lg hover:shadow-xl transition-all duration-300 text-green-600 hover:text-green-800"
          title="Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ"
        >
          <MessageSquare className="w-6 h-6" />
        </button>
      </header>

      {/* Main Content */}
      <main className="container mx-auto px-4">
        <div className="flex justify-center">
          {/* Microphone Button - Always Center */}
          <div className="flex items-center justify-center min-h-[400px]">
            <div className="flex flex-col items-center space-y-6">
              {/* Status Message */}
              {state.currentMessage && (
                <div className="bg-white p-4 rounded-lg shadow-lg max-w-md text-center animate-fade-in">
                  <p className="text-green-800 font-medium">
                    "{state.currentMessage}"
                  </p>
                </div>
              )}

              {/* Main Microphone Button */}
              <button
                onClick={handleMicrophoneClick}
                disabled={state.isProcessing}
                className={getButtonClasses()}
              >
                {renderIcon()}
                <span className="text-xs mt-1 px-2 text-center leading-tight">
                  {buttonText}
                </span>
              </button>

              {/* Error Message */}
              {state.error && (
                <div className="bg-red-100 border border-red-300 text-red-800 p-3 rounded-lg max-w-md text-center">
                  <p className="text-sm">{state.error}</p>
                </div>
              )}

              {/* Simple Status */}
              <div className="text-center">
                <div className={`inline-flex items-center px-3 py-1 rounded-full text-xs ${
                  state.microphonePermission ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
                }`}>
                  <div className={`w-2 h-2 rounded-full ml-2 ${
                    state.microphonePermission ? 'bg-green-500' : 'bg-red-500'
                  }`}></div>
                  {state.microphonePermission ? 'Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ú¯ÙØªÚ¯Ùˆ' : 'Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† ØºÛŒØ±ÙØ¹Ø§Ù„'}
                </div>
              </div>
            </div>
          </div>
        </div>
      </main>

      {/* Chat History Modal */}
      {showHistory && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50 p-4">
          <div className="bg-white rounded-xl shadow-2xl max-w-2xl w-full max-h-[80vh] overflow-hidden">
            <div className="flex items-center justify-between p-4 border-b border-gray-200">
              <h2 className="text-xl font-bold text-green-800">ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ</h2>
              <div className="flex items-center gap-2">
                {state.history.length > 0 && (
                  <button
                    onClick={() => {
                      if (confirm('Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯ØŸ')) {
                        dispatch({ type: 'CLEAR_HISTORY' });
                        // Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø§Ø² localStorage
                        if (typeof window !== 'undefined') {
                          localStorage.removeItem(`voice-history-${tenantKey}`);
                          console.log('ğŸ—‘ï¸ History cleared from storage');
                        }
                      }
                    }}
                    className="text-red-500 hover:text-red-700 text-sm px-3 py-1 rounded-lg hover:bg-red-50 transition-colors"
                  >
                    Ù¾Ø§Ú© Ú©Ø±Ø¯Ù†
                  </button>
                )}
                <button
                  onClick={() => setShowHistory(false)}
                  className="text-gray-500 hover:text-gray-700 text-2xl font-bold"
                >
                  Ã—
                </button>
              </div>
            </div>
            <div className="p-4 overflow-y-auto max-h-[60vh]">
              {state.history.length === 0 ? (
                <div className="text-center text-gray-500 py-8">
                  <MessageSquare className="w-16 h-16 mx-auto mb-4 opacity-20" />
                  <p>Ù‡Ù†ÙˆØ² Ú¯ÙØªÚ¯ÙˆÛŒÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª</p>
                </div>
              ) : (
                <div className="space-y-4">
                  {state.history.map((msg, index) => (
                    <div key={index} className="space-y-2">
                      {/* User Message */}
                      <div className="flex justify-end">
                        <div className="bg-green-100 text-green-800 rounded-lg p-3 max-w-[80%]">
                          <p className="text-sm font-semibold mb-1">Ø´Ù…Ø§:</p>
                          <p>{msg.user}</p>
                        </div>
                      </div>
                      {/* Robin Response */}
                      <div className="flex justify-start">
                        <div className="bg-gray-100 text-gray-800 rounded-lg p-3 max-w-[80%]">
                          <p className="text-sm font-semibold mb-1">Ø±Ø§Ø¨ÛŒÙ†:</p>
                          <p>{msg.robin}</p>
                        </div>
                      </div>
                    </div>
                  ))}
                </div>
              )}
            </div>
          </div>
        </div>
      )}

      {/* Footer */}
      <footer className="text-center py-8 mt-16">
        <p className="text-green-600">
          Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ¹Ø§Ù„ Ø§Ø³Øª - ÙÙ‚Ø· Ø´Ø±ÙˆØ¹ Ø¨Ù‡ ØµØ­Ø¨Øª Ú©Ù†ÛŒØ¯
        </p>
      </footer>
    </div>
  );
}
